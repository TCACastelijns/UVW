{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "def date_parser(s):\n",
    "    \"\"\"\n",
    "    Parse a date string using the log file's format. For example: '2015/10/16 11:25:59.000'\n",
    "    \"\"\"\n",
    "    without_ms = s.split('.')[0]\n",
    "    return datetime.datetime.strptime(without_ms, '%Y/%m/%d %H:%M:%S')\n",
    "\n",
    "log = pd.read_csv('data/log.csv', parse_dates=['startTime', 'completeTime'], date_parser=date_parser)\n",
    "\n",
    "# Events without an event type are pretty useless so we might as well drop them\n",
    "log.dropna(axis=0, subset=['event'], inplace=True)\n",
    "log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make sure the list of activities per session will be ordered by time\n",
    "log.sort_values(['sessionid', 'startTime'], ascending=[True, True], inplace=True)\n",
    "\n",
    "# Define aggregations when looking at each session\n",
    "aggregations = {'event': lambda x: list(x), \n",
    "                'startTime': 'first', \n",
    "                'completeTime': 'last', \n",
    "                'gender': 'first',\n",
    "                'agecategory': 'first'\n",
    "               }\n",
    "sessions = log.groupby('sessionid', as_index=False).agg(aggregations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def eliminate_leakage(event_list, including=True):\n",
    "    \"\"\"\n",
    "    Cut sessions at the point where a question is asked, (including the question itself or not).\n",
    "    If the trace does not include a question, return it unchanged.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        question_index = event_list.index('Question')\n",
    "        if including:\n",
    "            question_index = question_index + 1\n",
    "        return event_list[:question_index]\n",
    "    except ValueError:\n",
    "        return event_list\n",
    "    \n",
    "sessions['event'] = sessions['event'].apply(eliminate_leakage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "from collections import Counter\n",
    "\n",
    "def asked_question(event_list):\n",
    "    return int(event_list[-1] == 'Question')\n",
    "\n",
    "def age(age_cat):\n",
    "    mapping = {'30-39': 35, '50-65': 57, '40-49': 45, '18-29': 23}\n",
    "    return mapping[age_cat]\n",
    "\n",
    "def max_loops(event_list):\n",
    "    event_counter = Counter(event_list)\n",
    "    most_visited_page = max(event_counter, key=event_counter.get)\n",
    "    times_visited = event_counter[most_visited_page]\n",
    "    if times_visited == 1:\n",
    "        most_visited_page = None\n",
    "    return most_visited_page, times_visited \n",
    "    \n",
    "def hour(timestamp):\n",
    "    return timestamp.hour\n",
    "\n",
    "def gender(gender):\n",
    "    \"\"\"\n",
    "    This could be done directly on the DF but lets keep the same style for everything\n",
    "    \"\"\"\n",
    "    return int(gender == 'M')\n",
    "    \n",
    "# Create target variable - Did this session end up with a question?\n",
    "sessions['asked_question'] = sessions['event'].apply(asked_question)\n",
    "\n",
    "# Gender from character to int\n",
    "sessions['gender'] = sessions['gender'].apply(gender)\n",
    "\n",
    "# Age from category to int and rename column\n",
    "sessions['agecategory'] = sessions['agecategory'].apply(age)\n",
    "sessions.rename(columns={'agecategory': 'age'}, inplace=True)\n",
    "\n",
    "# Hour of day when the session took place.\n",
    "sessions['hour'] = sessions['startTime'].apply(hour)\n",
    "\n",
    "# Max number of page reoccurence within the sessions and the page mostly visited. \n",
    "# If each page was visited once then mostly visited will be None. The start syntax is interesting,\n",
    "# it allows the apply function to create multiple outputs. This could be useful for the TODO step\n",
    "# mentioned below.\n",
    "sessions['most_visited_page'], sessions['max_loops'] = zip(*sessions['event'].apply(max_loops))\n",
    "\n",
    "############################################# TODO ########################################################\n",
    "### We could use the 'most_visited' column to create smart dummy variables. For example something like: ### \n",
    "### Is the home page the mostly visited, or the same for other interesting pages.                       ###\n",
    "############################################# TODO ########################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "y = sessions['asked_question'].values\n",
    "# Include more columns in the future!\n",
    "X = sessions.drop(['asked_question', 'sessionid', 'startTime', 'completeTime', 'most_visited_page', 'event'], axis=1).values\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, kernel='lin')\n",
    "\n",
    "clf = svm.SVC()\n",
    "clf.fit(X_train, y_train)\n",
    "prediction = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use at own risk\n",
    "import matplotlib as plt\n",
    "\n",
    "def f_importances(coef, names):\n",
    "    imp = coef\n",
    "    imp,names = zip(*sorted(zip(imp,names)))\n",
    "    plt.barh(range(len(names)), imp, align='center')\n",
    "    plt.yticks(range(len(names)), names)\n",
    "    plt.show()\n",
    "    \n",
    "f_importances(clf.coef_, X.columns)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
