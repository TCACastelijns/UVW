{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages and load to orignal log of UWV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import random\n",
    "\n",
    "def date_parser(s):\n",
    "    \"\"\"\n",
    "    Parse a date string using the log file's format. For example: '2015/10/16 11:25:59.000'\n",
    "    \"\"\"\n",
    "    without_ms = s.split('.')[0]\n",
    "    return datetime.datetime.strptime(without_ms, '%Y/%m/%d %H:%M:%S')\n",
    "\n",
    "log = pd.read_csv('data/log.csv', parse_dates=['startTime', 'completeTime'], date_parser=date_parser)\n",
    "\n",
    "# Events without an event type are pretty useless so we might as well drop them\n",
    "log.dropna(axis=0, subset=['event'], inplace=True)\n",
    "log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sad_log_1Q=pd.read_csv('data/sad_log_1Q.csv', encoding= \"ISO-8859-1\")\n",
    "happy_log=pd.read_csv('data/happy_log.csv', encoding= \"ISO-8859-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sad_log_1Q['asked_question']=1\n",
    "happy_log['asked_question']=0\n",
    "log=pd.concat([happy_log, sad_log_1Q], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create session summary\n",
    "## Aggregate log by sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure the list of activities per session will be ordered by time\n",
    "log.sort_values(['sessionid', 'startTime'], ascending=[True, True], inplace=True)\n",
    "log['startTime']=log['completeTime']\n",
    "\n",
    "# Define aggregations when looking at each session\n",
    "aggregations = {'event': lambda x: list(x), \n",
    "                'startTime': 'first', \n",
    "                'completeTime': 'last', \n",
    "                'gender': 'first',\n",
    "                'agecategory': 'first',\n",
    "                'asked_question': 'first'\n",
    "               }\n",
    "sessions = log.groupby('sessionid', as_index=False).agg(aggregations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove reoccurences of questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eliminate_leakage(event_list, including=True):\n",
    "    \"\"\"\n",
    "    Cut sessions at the point where a question is asked, (including the question itself or not).\n",
    "    If the trace does not include a question, return it unchanged.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        question_index = event_list.index('Question')\n",
    "        if including:\n",
    "            question_index = question_index + 1\n",
    "        else:\n",
    "            question_index = question_index\n",
    "        return event_list[:question_index]\n",
    "    except ValueError:\n",
    "        return event_list\n",
    "    \n",
    "#sessions['event'] = sessions['event'].apply(eliminate_leakage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Age category, Max loops, hour, gender "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# If there is a question within a session, return a 1, else a 0\n",
    "def asked_question(event_list):\n",
    "    return int(event_list[-1] == 'Question')\n",
    "\n",
    "# Ordinal mapping of age categories\n",
    "def age(age_cat):\n",
    "    mapping = {'30-39': 35, '50-65': 57, '40-49': 45, '18-29': 23}\n",
    "    return mapping[age_cat]\n",
    "\n",
    "# This function returns:\n",
    "# 1) The most visisted page within the session\n",
    "# 2) The times that page is visited\n",
    "def max_loops(event_list):\n",
    "    event_counter = Counter(event_list)\n",
    "    most_visited_page = max(event_counter, key=event_counter.get)\n",
    "    times_visited = event_counter[most_visited_page]\n",
    "    if times_visited == 1:\n",
    "        most_visited_page = None\n",
    "        \n",
    "    inds=[index for index, value in enumerate(event_list) if value==most_visited_page]\n",
    "    if len(inds)==0:\n",
    "        avg_steps=0\n",
    "    else:\n",
    "        steps=np.diff(inds)\n",
    "        avg_steps=np.mean(steps)+1\n",
    "    return most_visited_page, times_visited, avg_steps\n",
    "\n",
    "# The hour of the timestamp can be seen as a feature\n",
    "def hour(timestamp):\n",
    "    return timestamp.hour\n",
    "\n",
    "# Gender of a customer\n",
    "def gender(gender):\n",
    "    \"\"\"\n",
    "    This could be done directly on the DF but lets keep the same style for everything\n",
    "    \"\"\"\n",
    "    return int(gender == 'M')\n",
    "\n",
    "    \n",
    "# Create target variable - Did this session end up with a question?\n",
    "#sessions['asked_question'] = sessions['event'].apply(asked_question)\n",
    "#sessions['event'] = sessions['event'].apply(eliminate_leakage,including=False)\n",
    "\n",
    "# Gender from character to int\n",
    "sessions['gender'] = sessions['gender'].apply(gender)\n",
    "\n",
    "# Age from category to int and rename column\n",
    "sessions['agecategory'] = sessions['agecategory'].apply(age)\n",
    "sessions.rename(columns={'agecategory': 'age'}, inplace=True)\n",
    "\n",
    "# Hour of day when the session took place.\n",
    "sessions['startTime']=sessions['startTime'].apply(pd.to_datetime)\n",
    "sessions['completeTime']=sessions['completeTime'].apply(pd.to_datetime)\n",
    "sessions['hour'] = sessions['startTime'].apply(hour)\n",
    "\n",
    "timediff=sessions['completeTime']-sessions['startTime']\n",
    "sessions['timediff'] = timediff.apply(lambda x: x.seconds)\n",
    "\n",
    "# Max number of page reoccurence within the sessions and the page mostly visited. \n",
    "# If each page was visited once then mostly visited will be None. The start syntax is interesting,\n",
    "# it allows the apply function to create multiple outputs. This could be useful for the TODO step\n",
    "# mentioned below.\n",
    "sessions['most_visited_page'], sessions['max_loops'], sessions['avg_steps'] = zip(*sessions['event'].apply(max_loops))\n",
    "\n",
    "############################################# TODO ########################################################\n",
    "### We could use the 'most_visited' column to create smart dummy variables. For example something like: ### \n",
    "### Is the home page the mostly visited, or the same for other interesting pages.                       ###\n",
    "############################################# TODO ########################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Presence of trigger events by Markov Chain model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trigger_events= ['Visit page mijn_werkmap','Visit page home','Visit page taken',\n",
    "                 'Visit page vacatures_bij_mijn_cv','Visit page mijn_berichten',\n",
    "                 'Visit page werkmap','Visit page mijn_documenten',\n",
    "                 'Visit page mijn_sollicitaties','Visit page mijn_cv',\n",
    "                 'Visit page mijn_tips','Visit page inschrijven',\n",
    "                 'Visit page foutopgetreden.html']\n",
    "\n",
    "for event in trigger_events:\n",
    "    sessions[event]=sessions['event'].apply(lambda x: int(event in x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning to predict questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix, classification_report\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "y = sessions['asked_question']\n",
    "# Include more columns in the future!\n",
    "X = sessions.drop(['asked_question', 'sessionid', 'startTime', 'completeTime', 'most_visited_page', 'event'], axis=1)\n",
    "features=X.columns\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'max_depth': [2, 3, 4, 5, 6, 7, 8]}\n",
    "#param_grid = {'C':[1,10]}\n",
    "\n",
    "clf=RandomForestClassifier()\n",
    "grid = GridSearchCV(clf, param_grid, cv=3,scoring='roc_auc',n_jobs=3, verbose=3)\n",
    "model=grid.fit(X_train, y_train)\n",
    "    \n",
    "best_parameters, score, _ = max(model.grid_scores_, key=lambda x: x[1])\n",
    "print('Normalized AUC:', score)\n",
    "for param_name in sorted(best_parameters.keys()):\n",
    "    print(\"%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestClassifier(max_depth=best_parameters[param_name], random_state=42)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use at own risk\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def f_importances(coef, names):\n",
    "    imp = coef\n",
    "    imp,names = zip(*sorted(zip(imp,names)))\n",
    "    plt.barh(range(len(names)), imp, align='center')\n",
    "    plt.yticks(range(len(names)), names)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    plt.savefig('Important features')\n",
    "    \n",
    "f_importances(model.feature_importances_, features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predictions=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "12px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
